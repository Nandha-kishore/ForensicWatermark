!pip install ultralytics opencv-python matplotlib numpy


import time  
from ultralytics import YOLO
import cv2
import numpy as np
from matplotlib import pyplot as plt
from urllib.request import urlretrieve
import json


startTime = time.time()

# Load the YOLOv8 model
model = YOLO('yolov8l.pt')

# Get the URL of the Image 
inputImage_url = input("Enter the image URL: ")
inputImage_path = 'input_image.jpg'
urlretrieve(inputImage_url, inputImage_path)

# Read the input image with OpenCV
image = cv2.imread(inputImage_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Perform inference
inference_start = time.time()
results = model.predict(image_rgb)
inference_end = time.time()
inference_duration = inference_end - inference_start
print(f"Model Inference Time: {inference_duration:.4f} seconds")

# Get the RGB Values to be filled
r_value = int(input("Enter the red value (0-255): "))
g_value = int(input("Enter the green value (0-255): "))
b_value = int(input("Enter the blue value (0-255): "))

# Ask for a key to store the RGB values
rgb_key = input("Enter a key to store the RGB values: ")

# Define a function to save RGB values to a local file
def save_rgb_to_file(key, r, g, b, filename='key_rgb_values.json'):
    rgb_data = {}
    
    # Try to read the existing data, if the file exists
    try:
        with open(filename, 'r') as file:
            rgb_data = json.load(file)
    except FileNotFoundError:
        pass
    
    # Store the new RGB values against the key
    rgb_data[key] = {'red': r, 'green': g, 'blue': b}
    
    # Write the updated data back to the file
    with open(filename, 'w') as file:
        json.dump(rgb_data, file, indent=4)
    
    print(f"RGB values for key '{key}' saved successfully to {filename}")

# Save the RGB values to a file
save_rgb_to_file(rgb_key, r_value, g_value, b_value)

# Define the function to fill the area with a custom color using Canny edge detection
def fill_area_with_custom_color(crop, b_value, g_value, r_value):
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Apply Canny edge detection
    edges = cv2.Canny(blurred, 50, 150)  

    # Dilate the edges to close small gaps
    kernel = np.ones((5,5), np.uint8)
    dilated_edges = cv2.dilate(edges, kernel, iterations=2)

    # Find contours from the dilated edges
    contours, _ = cv2.findContours(dilated_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Create a mask for the contours
    mask = np.zeros(crop.shape[:2], dtype=np.uint8)

    # Fill the contours with white on the mask
    for contour in contours:
        if cv2.contourArea(contour) > 1000:  
            cv2.drawContours(mask, [contour], 0, 255, -1)

    # Create a custom color overlay based on user input
    custom_overlay = np.zeros_like(crop)
    custom_overlay[:] = (b_value, g_value, r_value)  # BGR color format

    # Apply the mask to the custom color overlay
    custom_filled_area = cv2.bitwise_and(custom_overlay, custom_overlay, mask=mask)

    # Combine the original image with the custom filled area
    result = cv2.addWeighted(crop, 1, custom_filled_area, 0.5, 0)

    return result

# Creating a copy of the original image
final_image = image.copy()

# Display detected objects and store class names for user input
class_names_detected = []
for result in results:
    for box in result.boxes:
        class_name = result.names[int(box.cls)]
        x1, y1, x2, y2 = map(int, box.xyxy[0])

        class_names_detected.append(class_name)

        # Draw bounding box (green) and put class name on the display image
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, class_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

# Display the image with bounding boxes and class tags
image_rgb_display = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
plt.figure(figsize=(12, 8))
plt.imshow(image_rgb_display)
plt.axis('off')
plt.show()

# Add a 5-second delay before asking for the object to be selected, This is because the plt.show is taking some time to display the image
time.sleep(5)

#  Ask the user to select the tag after displaying the image
selected_tag = input(f"Select the tag to color from the detected objects {set(class_names_detected)}: ")

# Process detected objects again to fill selected area
processing_start = time.time()
for result in results:
    for box in result.boxes:
        class_name = result.names[int(box.cls)]
        x1, y1, x2, y2 = map(int, box.xyxy[0])

        if class_name.lower() == selected_tag.lower():
            # Crop the detected region from the final image (without boxes)
            crop = final_image[y1:y2, x1:x2]

            # Fill the area with custom color using Canny detector
            filled_crop = fill_area_with_custom_color(crop, b_value, g_value, r_value)

            # Replace the cropped region in the final image (without boxes)
            final_image[y1:y2, x1:x2] = filled_crop

# Convert to RGB for displaying with matplotlib
final_image_rgb = cv2.cvtColor(final_image, cv2.COLOR_BGR2RGB)

# Display the final image with the filled area and no bounding boxes or tags
plt.figure(figsize=(12, 8))
plt.imshow(final_image_rgb)
plt.axis('off')
plt.show()

# Save the output image without green boxes and labels
output_image_path = 'output_image.jpg'
cv2.imwrite(output_image_path, final_image)

processing_end = time.time()
processing_duration = processing_end - processing_start
total_duration = time.time() - startTime

# Print performance results
print(f"Output image saved as {output_image_path}")
print(f"Processing Time: {processing_duration:.4f} seconds")
print(f"Total Execution Time: {total_duration:.4f} seconds")
